{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from itertools import chain\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import zipfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import librosa\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "import IPython.display as ipd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tabulate import tabulate\n",
    "from IPython.display import Audio\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "from scipy.io.wavfile import read\n",
    "\n",
    "from linformer_pytorch import Linformer\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import tqdm\n",
    "import IPython.display\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechCommandsDataset(Dataset):\n",
    "    \"\"\"Google Speech Commands dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, split,transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the data files.\n",
    "            split    (string): In [\"train\", \"valid\", \"test\"].\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "\n",
    "        self.number_of_classes = len(self.get_classes())\n",
    "\n",
    "        self.class_to_file = defaultdict(list)\n",
    "\n",
    "        self.valid_filenames = self.get_valid_filenames()\n",
    "        self.test_filenames = self.get_test_filenames()\n",
    "\n",
    "        for c in self.get_classes():\n",
    "            file_name_list = sorted(os.listdir(self.root_dir + \"dataset/\" + c))\n",
    "            for filename in file_name_list:\n",
    "                if split == \"train\":\n",
    "                    if (filename not in self.valid_filenames[c]) and (filename not in self.test_filenames[c]):\n",
    "                        self.class_to_file[c].append(filename)\n",
    "                elif split == \"valid\":\n",
    "                    if filename in self.valid_filenames[c]:\n",
    "                        self.class_to_file[c].append(filename)\n",
    "                elif split == \"test\":\n",
    "                    if filename in self.test_filenames[c]:\n",
    "                        self.class_to_file[c].append(filename)\n",
    "                else:\n",
    "                    raise ValueError(\"Invalid split name.\")\n",
    "\n",
    "        self.filepath_list = list()\n",
    "        self.label_list = list()\n",
    "        for cc, c in enumerate(self.get_classes()):\n",
    "            f_extension = sorted(list(self.class_to_file[c]))\n",
    "            l_extension = [cc for i in f_extension]\n",
    "            f_extension = [self.root_dir + \"dataset/\" + c + \"/\" + filename for filename in f_extension]\n",
    "            self.filepath_list.extend(f_extension)\n",
    "            self.label_list.extend(l_extension)\n",
    "        self.number_of_samples = len(self.filepath_list)\n",
    "    def __len__(self):\n",
    "        return self.number_of_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = np.zeros((16000, ), dtype=np.float32)\n",
    "\n",
    "        sample_file = self.filepath_list[idx]\n",
    "\n",
    "        sample_from_file = read(sample_file)[1]\n",
    "        sample[:sample_from_file.size] = sample_from_file\n",
    "        sample = sample.reshape((16000, ))\n",
    "        \n",
    "        # It is better to stick to PyTorch functions\n",
    "        # I swapped the `libroseÂ´ mfcc resampling with this PyTorch alternative\n",
    "        # however, the parameters are the same\n",
    "        mfcc_transform = T.MFCC(\n",
    "            sample_rate=16000,\n",
    "            n_mfcc=20,\n",
    "            melkwargs={\n",
    "              'n_fft': 2048,\n",
    "              'hop_length': 512})\n",
    "        \n",
    "        #print(f\">> Sample Shape: {sample.shape}\")\n",
    "        \n",
    "        sample = torch.transpose(mfcc_transform(torch.tensor(sample)), 0, 1)\n",
    "        \n",
    "        #sample = librosa.feature.mfcc(y=sample, sr=16000, hop_length=512, n_fft=2048).transpose().astype(np.float32)\n",
    "        \n",
    "        # we apply the augmentations on the sample if it is defined\n",
    "        if self.transform:\n",
    "            sample = self.transform(samples=sample.reshape(32, 1, 20), sample_rate=16000)\n",
    "            sample = sample.reshape(32, 20)\n",
    "        \n",
    "        #print(f\">> Sample Shape: {sample.shape}\")\n",
    "        #print(\"--\"*10)\n",
    "\n",
    "        label = self.label_list[idx]\n",
    "\n",
    "        return sample, label\n",
    "\n",
    "    def get_classes(self):\n",
    "        return [\"zero\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\",\"right\", \n",
    "                \"left\", \"up\", \"down\", \"forward\", \"backward\", \"yes\", \"no\", \"stop\", \"start\", \"enable\", \n",
    "                \"disable\", \"ok\", \"cancel\", \"open\", \"close\", \"zoom in\", \"zoom out\", \"previous\", \"next\", \n",
    "                \"send\", \"receive\", \"move\", \"rotate\", \"record\", \"enter\", \"digit\", \"direction\", \"options\", \"undo\"]\n",
    "\n",
    "    def get_valid_filenames(self):\n",
    "        class_names = self.get_classes()\n",
    "\n",
    "        class_to_filename = defaultdict(set)\n",
    "        with open(self.root_dir + \"dataset/val.txt\", \"r\") as fp:\n",
    "            for line in fp:\n",
    "                clean_line = line.strip().split(\"/\")\n",
    "\n",
    "                if clean_line[0] in class_names:\n",
    "                    class_to_filename[clean_line[0]].add(clean_line[1])\n",
    "\n",
    "        return class_to_filename\n",
    "\n",
    "    def get_test_filenames(self):\n",
    "        class_names = self.get_classes()\n",
    "\n",
    "        class_to_filename = defaultdict(set)\n",
    "        with open(self.root_dir + \"dataset/test.txt\", \"r\") as fp:\n",
    "            for line in fp:\n",
    "                clean_line = line.strip().split(\"/\")\n",
    "\n",
    "                if clean_line[0] in class_names:\n",
    "                    class_to_filename[clean_line[0]].add(clean_line[1])\n",
    "\n",
    "        return class_to_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_audiomentations import Compose, Gain, PolarityInversion\n",
    "\n",
    "# Initialize augmentation callable\n",
    "train_transforms = Compose(\n",
    "    transforms=[\n",
    "        Gain(\n",
    "            min_gain_in_db=-15.0,\n",
    "            max_gain_in_db=5.0,\n",
    "            p=0.5,\n",
    "        ),\n",
    "        PolarityInversion(p=0.5)\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    transforms=[\n",
    "        Gain(\n",
    "            min_gain_in_db=-15.0,\n",
    "            max_gain_in_db=5.0,\n",
    "            p=0.5,\n",
    "        ),\n",
    "        PolarityInversion(p=0.5)\n",
    "    ]\n",
    ")\n",
    "test_transforms = Compose(\n",
    "    transforms=[\n",
    "        Gain(\n",
    "            min_gain_in_db=-15.0,\n",
    "            max_gain_in_db=5.0,\n",
    "            p=0.5,\n",
    "        ),\n",
    "        PolarityInversion(p=0.5)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder=\"Arabic_Speech_command/\"\n",
    "\n",
    "train_dataset = SpeechCommandsDataset(dataset_folder, \"train\")\n",
    "\n",
    "valid_dataset = SpeechCommandsDataset(dataset_folder, \"valid\")\n",
    "\n",
    "test_dataset = SpeechCommandsDataset(dataset_folder, \"test\")\n",
    "\n",
    "### Augmented Datasets ###\n",
    "# Note we should concatenate both the non-augmented and the augmented training datasets\n",
    "\n",
    "train_dataset_aug = ConcatDataset([SpeechCommandsDataset(dataset_folder, \"train\", transform=train_transforms),\n",
    "                                  train_dataset])\n",
    "\n",
    "valid_dataset_aug = SpeechCommandsDataset(dataset_folder, \"valid\", transform=val_transforms)\n",
    "\n",
    "test_dataset_aug  = SpeechCommandsDataset(dataset_folder, \"test\", transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                           batch_size=batch_size,\n",
    "                           shuffle=True)\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                           batch_size=batch_size,\n",
    "                           shuffle=True)\n",
    "\n",
    "test_loader  = DataLoader(dataset=test_dataset,\n",
    "                           batch_size=batch_size,\n",
    "                           shuffle=True)\n",
    "\n",
    "### Augmented Dataloaders + non-augmented ###\n",
    "\n",
    "train_loader_aug = DataLoader(dataset=train_dataset_aug,\n",
    "                           batch_size=batch_size,\n",
    "                           shuffle=True)\n",
    "\n",
    "valid_loader_aug = DataLoader(dataset=valid_dataset_aug,\n",
    "                           batch_size=batch_size,\n",
    "                           shuffle=True)\n",
    "\n",
    "test_loader_aug  = DataLoader(dataset=test_dataset_aug,\n",
    "                           batch_size=batch_size,\n",
    "                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training dataset -- dataloader lengths: {len(train_dataset)} -- {len(train_loader)}\")\n",
    "\n",
    "print(f\"Validation dataset -- dataloader lengths: {len(valid_dataset)} -- {len(valid_loader)}\")\n",
    "\n",
    "print(f\"Testing dataset -- dataloader lengths: {len(test_dataset)} -- {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetworkModel(nn.Module):\n",
    "    \"\"\"Neural network model (Transformer-based).\n",
    "\n",
    "    Args:\n",
    "        idim (int): Input feature dimension.\n",
    "        d_att (int): Attention dimension.\n",
    "        n_heads (int): The number of attention heads.\n",
    "        d_ff (int): Dimension of feed forward network.\n",
    "        dropout_rate (float): Dropout rate.\n",
    "        n_layers (int): The number of encoder layers.\n",
    "        d_linear (int): Dimension of a hidden layer of the classifier.\n",
    "        n_classes (int): The number of the output classes.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        idim=13,\n",
    "        d_att=64,\n",
    "        n_heads=2,\n",
    "        d_ff=512,\n",
    "        dropout_rate=0.1,\n",
    "        n_layers=3,\n",
    "        n_classes=40\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.subsampling = Subsampling(idim=idim, d_att=d_att)\n",
    "        self.positional_encoding = PositionalEncoding()\n",
    "        self.encoder_layers = nn.Sequential()\n",
    "        for i in range(n_layers):\n",
    "            self.encoder_layers.add_module(\n",
    "                f'EncoderLayer{i}', \n",
    "                TransformerEncoderLayer(d_att, n_heads, d_ff, dropout_rate)\n",
    "            )\n",
    "        self.norm = nn.LayerNorm(d_att)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.out = nn.Linear(d_att, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Recognize the input speech commands.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input features (batch, tmax, idim).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Recognized classes (batch, num_classes).\n",
    "\n",
    "        \"\"\"   \n",
    "        # Transformer encoder\n",
    "        x = self.subsampling(x)\n",
    "        x = self.positional_encoding(x)\n",
    "        x = self.encoder_layers(x)\n",
    "        x = self.norm(x)\n",
    "        # Classifier\n",
    "        x = torch.mean(x, dim=1)  # (b, t, d_att) -> (b, d_att)\n",
    "        x = self.dropout(x)\n",
    "        x = self.out(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    \"\"\"A Transformer encoder layer.\n",
    "\n",
    "    Args:\n",
    "        d_att (int): Attention dimension.\n",
    "        d_head (int): The number of attention heads.\n",
    "        d_ff (int): Dimension of feed forward network.\n",
    "        dropout_rate (float): Dropout rate.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_att, d_head, d_ff, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadAttention(d_att, d_head, dropout_rate)\n",
    "        self.ff = FeedForward(d_att, d_ff, dropout_rate)\n",
    "        self.norm_mha = nn.LayerNorm(d_att)\n",
    "        self.norm_ff = nn.LayerNorm(d_att)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Pre-encoded inputs (batch, tmax, d_att).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Encoded outputs (batch, tmax, d_att).\n",
    "\n",
    "        \"\"\"\n",
    "        # Multi-Head Attention\n",
    "        res = x\n",
    "        x = self.norm_mha(x)\n",
    "        x = res + self.dropout(self.mha(x, x, x))\n",
    "\n",
    "        # Feed-Forward\n",
    "        res = x\n",
    "        x = self.norm_ff(x)\n",
    "        x = res + self.dropout(self.ff(x))\n",
    "\n",
    "        return x\n",
    "class Subsampling(nn.Module):\n",
    "    \"\"\"Convolutional Subsampling.\n",
    "\n",
    "    Args:\n",
    "        idim (int): Input feature dimension.\n",
    "        d_att (int): Attention dimension.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, idim, d_att):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, d_att, kernel_size=(3, 3), stride=(2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(d_att, d_att, kernel_size=(3, 3), stride=(2, 2)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.linear = nn.Linear(256, d_att)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input features (batch, tmax, idim).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Subsampled features (batch, tmax', d_att).\n",
    "\n",
    "        \"\"\"\n",
    "        x = x.unsqueeze(1)  # (b, t, idim) -> (b, c=1, t, idim)\n",
    "        x = self.conv(x)\n",
    "        b, c, t, f = x.size()\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        x = x.transpose(1, 2).contiguous().view(b, t, c * f)  # (b, c, t, f) -> (b, t, c * t)\n",
    "        \n",
    "        x = self.linear(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Positional Encoding.\n",
    "\n",
    "    Args:\n",
    "        idim (int): Input feature dimension.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "           super().__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            x: (torch.Tensor): Subsampled features (batch, tmax, d_att).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Encoded features (batch, tmax, d_att).\n",
    "\n",
    "        \"\"\"\n",
    "        _, tmax, d_att = x.size()\n",
    "        pos = torch.arange(0, tmax, dtype=torch.float32).unsqueeze(1)\n",
    "        pe = torch.zeros(1, tmax, d_att, dtype=torch.float32).to(x.device)\n",
    "        pe[:, :, 0::2] = torch.sin(pos / torch.pow(10000, torch.arange(0, d_att, 2) / d_att))\n",
    "        pe[:, :, 1::2] = torch.cos(pos / torch.pow(10000, torch.arange(0, d_att, 2) / d_att))\n",
    "        x = x + pe\n",
    "\n",
    "        return x\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"Multi-Head Attention.\n",
    "\n",
    "    Args:\n",
    "        d_att (int): Dimension of attention.\n",
    "        d_head (int): The number of attention heads.\n",
    "        dropout_rate (float): Dropout rate.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_att, n_heads, dropout_rate):\n",
    "        super().__init__()\n",
    "        self.linear_q = nn.Linear(d_att, d_att)\n",
    "        self.linear_k = nn.Linear(d_att, d_att)\n",
    "        self.linear_v = nn.Linear(d_att, d_att)\n",
    "        self.linear_head = nn.Linear(d_att, d_att)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.n_heads = n_heads\n",
    "        self.d_comn = d_att // self.n_heads\n",
    "\n",
    "    def forward(self, q, k, v):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            q: (torch.Tensor): Query (batch, tmax, d_att).\n",
    "            k: (torch.Tensor): Key (batch, tmax, d_att).\n",
    "            v: (torch.Tensor): Value (batch, tmax, d_att).\n",
    "            Returns:\n",
    "            torch.Tensor: Output shape (batch, tmax, d_att).\n",
    "\n",
    "        \"\"\"\n",
    "        # Linear\n",
    "        qw = self.linear_q(q)\n",
    "        kw = self.linear_k(k)\n",
    "        vw = self.linear_v(v)\n",
    "\n",
    "        # Reshape tensor (b, t, d_att) -> (b, n_heads, t, d_comn)\n",
    "        b, t, d_att = q.size()\n",
    "        qw = qw.view(b, t, self.n_heads, self.d_comn).transpose(1, 2)\n",
    "        kw = kw.view(b, t, self.n_heads, self.d_comn).transpose(1, 2)\n",
    "        vw = vw.view(b, t, self.n_heads, self.d_comn).transpose(1, 2)\n",
    "\n",
    "        # Dot-attention\n",
    "        matmul = torch.matmul(qw, kw.transpose(2, 3)) \n",
    "        scale = matmul / torch.sqrt(torch.tensor(self.d_comn))\n",
    "        softmax = torch.softmax(scale, dim=-1)\n",
    "        att = torch.matmul(self.dropout(softmax), vw)  # (b, n_heads, t, d_comn)\n",
    "\n",
    "        # Concatenate\n",
    "        att = att.transpose(1, 2).contiguous().view(b, -1, self.n_heads * self.d_comn)  # (b, t, d_att)\n",
    "\n",
    "        # Linear\n",
    "        mha = self.linear_head(att)\n",
    "\n",
    "        return mha\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    \"\"\"Feed-Forward Network.\n",
    "\n",
    "    Args:\n",
    "        d_ff (int): Dimension of feed-forward network.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_att, d_ff, dropout_rate):\n",
    "        super().__init__()\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(d_att, d_ff), nn.ReLU(), nn.Dropout(dropout_rate), nn.Linear(d_ff, d_att)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            x: (torch.Tensor): Input shape (batch, tmax, d_att).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output shape (batch, tmax, d_att).\n",
    "\n",
    "        \"\"\"\n",
    "        return self.ff(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some metric lists\n",
    "def train(model, optimizer, train_loader, valid_loader, \n",
    "          criterion, results_dir='result', epochs=5, plot=False):\n",
    "    \n",
    "    #store evaluation metrics in these lists\n",
    "    train_acc_list = []\n",
    "    train_loss_list = []\n",
    "    dev_acc_list = []\n",
    "    dev_loss_list = []\n",
    "    \n",
    "    # best loss tracking for model checkpointing\n",
    "    best_loss = float(\"inf\")\n",
    "\n",
    "    # Train the model\n",
    "    training_start_time = time.time()\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        batch_train_loss = 0\n",
    "        batch_train_acc = 0\n",
    "        batch_dev_loss = 0\n",
    "        batch_dev_acc = 0\n",
    "\n",
    "        # Training\n",
    "        model.train()\n",
    "        for feats, labels in train_loader:\n",
    "            feats, labels = feats.to(device), labels.to(device)\n",
    "\n",
    "            # Reset gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward\n",
    "            outputs = model(feats)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward\n",
    "            loss.backward()\n",
    "\n",
    "            # Update weights\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_train_loss += loss.item()\n",
    "            batch_train_acc += (outputs.max(1)[1] == labels).sum().item()\n",
    "\n",
    "        train_loss_list.append(batch_train_loss / len(train_loader))\n",
    "        train_acc_list.append(batch_train_acc / len(train_loader.dataset))\n",
    "        # Validation\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for feats, labels in valid_loader:\n",
    "                feats, labels = feats.to(device), labels.to(device)\n",
    "\n",
    "                # Forward\n",
    "                outputs = model(feats)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                batch_dev_loss += loss.item()\n",
    "                batch_dev_acc += (outputs.max(1)[1] == labels).sum().item()\n",
    "\n",
    "        dev_loss_list.append(batch_dev_loss / len(valid_loader))\n",
    "        dev_acc_list.append(batch_dev_acc / len(valid_loader.dataset))\n",
    "            \n",
    "        ipd.clear_output()\n",
    "\n",
    "        # Print statistics\n",
    "        print(\n",
    "            \"Epoch: {}/{} - train_loss: {:.4f} - train_acc: {:.4f} - dev_loss: {:.4f} - dev_acc: {:.4f}\".format(\n",
    "                epoch+1, epochs, train_loss_list[-1], train_acc_list[-1], dev_loss_list[-1], dev_acc_list[-1]\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # # plot results if flag is True\n",
    "        if plot:\n",
    "            fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(20, 6.5))\n",
    "\n",
    "            ax[0].plot(range(len(train_loss_list)), train_loss_list, label='train loss')\n",
    "            ax[0].plot(range(len(dev_loss_list)), dev_loss_list, label='val loss')\n",
    "            ax[0].set_title('Loss Evolution')\n",
    "\n",
    "            ax[1].plot(range(len(train_acc_list)), train_acc_list, label='train accuracy')\n",
    "            ax[1].plot(range(len(dev_acc_list)), dev_acc_list, label='val accuracy')\n",
    "            ax[1].set_title('Accuracy Evolution')\n",
    "\n",
    "            ax[0].legend()\n",
    "            ax[1].legend()\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "    # Save the training time\n",
    "    training_time = time.time() - training_start_time\n",
    "    print(f\">> Training Time: {training_time}\")\n",
    "    # Make a directory to save the results\n",
    "    \n",
    "    if not os.path.isdir(\"result\"):\n",
    "        os.makedirs(\"result\")\n",
    "    # Save the best model\n",
    "    if best_loss > dev_loss_list[-1]:\n",
    "        torch.save(model.state_dict(), os.path.join(\"result\", \"model_best_loss\"))\n",
    "        best_loss = dev_loss_list[-1]\n",
    "    \n",
    "    with open(\"result/training_time.txt\", \"w\") as time_f:\n",
    "        time_f.write(f\"training time = {int(training_time)} (sec)\\n\")\n",
    "        \n",
    "def test(model, test_loader, criterion, plot=False):\n",
    "    best_loss = float(\"inf\")\n",
    "\n",
    "    # Test\n",
    "    test_start_time = time.time()\n",
    "    \n",
    "    batch_test_loss = 0\n",
    "    batch_test_acc = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for feats, labels in test_loader:\n",
    "            feats, labels = feats.to(device), labels.to(device)\n",
    "\n",
    "            # Forward\n",
    "            outputs = model(feats)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            batch_test_loss += loss.item()\n",
    "            batch_test_acc += (outputs.max(1)[1] == labels).sum().item()\n",
    "\n",
    "    test_mean_loss = batch_test_loss / len(test_loader.dataset)\n",
    "    test_mean_acc = batch_test_acc / len(test_loader.dataset)\n",
    "\n",
    "    # Print statistics\n",
    "    print(\n",
    "        \"test_loss: {:.4f} - test_acc: {:.4f}\".format(\n",
    "            test_mean_loss, test_mean_acc\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Print out test time\n",
    "    test_time = time.time() - test_start_time\n",
    "    print(f\">> Test Time: {test_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Validation Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Train Data (non-augmented) with Validation Data (Augmented)\n",
    "# We can notice that the validation accuracy stays low at a value of ~ 0.06 \n",
    "# On the other hand, the validation loss increases and reaches a value of +5.33\n",
    "\n",
    "# Build a model\n",
    "baseline_model = NeuralNetworkModel().to(device)\n",
    "print(f\"# model parameters: {sum(p.numel() for p in baseline_model.parameters()):,}\")\n",
    "\n",
    "# Define an optimizer and a loss function\n",
    "optimizer = optim.Adam(baseline_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "baseline_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "train(model=baseline_model, optimizer=optimizer, \n",
    "      train_loader=train_loader, valid_loader=valid_loader_aug, \n",
    "      criterion=baseline_loss_fn, epochs=epochs, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Data (augmented) with Validation Data (non-Augmented)\n",
    "# We can notice that the max validation accuracy reaches a value of +80%\n",
    "\n",
    "# Build a model\n",
    "aug_model = NeuralNetworkModel().to(device)\n",
    "print(f\"# model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Define an optimizer and a loss function\n",
    "optimizer = optim.Adam(aug_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "aug_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "train(model=aug_model, optimizer=optimizer, \n",
    "      train_loader=train_loader_aug, valid_loader=valid_loader, \n",
    "      criterion=loss_fn, epochs=epochs, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Data (augmented) with Validation Data (Augmented)\n",
    "# We can notice that the max accuracy is reaching a value of ~ 77%\n",
    "\n",
    "# Build a model\n",
    "aug_model = NeuralNetworkModel().to(device)\n",
    "print(f\"# model parameters: {sum(p.numel() for p in aug_model.parameters()):,}\")\n",
    "\n",
    "# Define an optimizer and a loss function\n",
    "optimizer = optim.Adam(aug_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "aug_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "train(model=aug_model, optimizer=optimizer, \n",
    "      train_loader=train_loader_aug, valid_loader=valid_loader_aug, \n",
    "      criterion=aug_loss_fn, epochs=epochs, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing the model with the test augmented data\n",
    "\n",
    "test(model=aug_model, test_loader=test_loader_aug, criterion=aug_loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing the model with the test augmented data\n",
    "\n",
    "test(model=baseline_model, test_loader=test_loader_aug, criterion=baseline_loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing the model with the test non-augmented data\n",
    "\n",
    "test(model=aug_model, test_loader=test_loader, criterion=aug_loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing the model with the test non-augmented data\n",
    "\n",
    "test(model=baseline_model, test_loader=test_loader, criterion=baseline_loss_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_venv",
   "language": "python",
   "name": "project_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
